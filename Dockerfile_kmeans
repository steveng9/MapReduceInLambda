FROM apache/spark-py AS build-1
USER root
WORKDIR /tmp
RUN apt-get update
RUN apt-get install nano
RUN pip3 install pyspark==3.4.0
RUN pip install boto3
RUN pip install numpy

ARG ACCESS_KEY
ARG SECRET_KEY

COPY hadoop-aws-3.2.0.jar /opt/spark/jars/
COPY aws-java-sdk-bundle-1.11.375.jar /opt/spark/jars/
COPY container_pyspark_kmeans.py container_pyspark_kmeans.py
COPY Inspector.py Inspector.py
COPY utils.py utils.py


ENV ACCESS_KEY=${ACCESS_KEY}
ENV SECRET_KEY=${SECRET_KEY}
ENV SPARK_HOME=/opt/spark
ENV HADOOP_CONF_DIR=$SPARK_HOME/conf

FROM build-1 AS build-2
CMD ["python3", "container_pyspark_kmeans.py"]
#ENTRYPOINT ["/bin/bash"]
